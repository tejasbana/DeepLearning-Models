{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Caltech256 Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMneLQc4bmDu/y73Q/7luuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejasbana/DeepLearning-Models/blob/main/Caltech256_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AmDu4VY9HuS"
      },
      "source": [
        "# Caltech256 Classification using Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwelBGZQ8WEG"
      },
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.utils import make_grid\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HowpfPgB9mX7"
      },
      "source": [
        "dataset = torchvision.datasets.Caltech256('./', download=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxH-6Clj-qMv"
      },
      "source": [
        "path = \"./caltech256/256_ObjectCategories\"\n",
        "print(len(os.listdir(path)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDGikOdI_F_F"
      },
      "source": [
        "pair_name = {}\n",
        "for i, dir in enumerate(os.listdir(path)):\n",
        "    # print(str(dir) + \" : \" + str(len(os.listdir(path+\"/\"+dir))))\n",
        "    pair_name[dir] = len(os.listdir(path + \"/\" + dir))\n",
        "    if i == 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-I36KVO_YmA"
      },
      "source": [
        "# Plot the Class distribution\n",
        "sns.barplot( data = pd.DataFrame.from_dict([pair_name]).melt(), \n",
        "             x = \"variable\", y=\"value\"\n",
        "             ).set_title(\"Class Distirbution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--n3qfJrHzT8"
      },
      "source": [
        "# Data Transformation\n",
        "states = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "\n",
        "train_tt = tt.Compose([tt.ToTensor(), tt.RandomHorizontalFlip(), \n",
        "                       tt.Resize((64,64)), tt.Normalize(*states)])\n",
        "\n",
        "test_tt = tt.Compose([tt.ToTensor(), \n",
        "                       tt.Resize((64,64)), tt.Normalize(*states)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6NatTBSBXsu"
      },
      "source": [
        "data_path = \"/content/caltech256/256_ObjectCategories\" \n",
        "batch_size = 512\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(data_path, transform= train_tt)\n",
        "\n",
        "train_size = int( 0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True,\n",
        "                                           batch_size = batch_size,\n",
        "                                           num_workers=2,\n",
        "                                           pin_memory=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size= 2*batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUKBLfUMJ9jb"
      },
      "source": [
        "def show_image(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12,12))\n",
        "        ax.set_xticks([]); ax.set_yticks([]);\n",
        "        ax.imshow( make_grid(images[:64], nrow=8).permute(1,2,0))\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tkq6H2vKqx-"
      },
      "source": [
        "show_image(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xDE-jPgFCvy"
      },
      "source": [
        "def get_default_device():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\")\n",
        "    else:\n",
        "        return torch.device(\"cpu\")\n",
        "\n",
        "def to_device(data, device):\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        return [ to_device(x, device) for x in data]\n",
        "    else:\n",
        "        return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for batch in self.dl:\n",
        "            yield to_device(batch, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d9dukSGLWV"
      },
      "source": [
        "device = get_default_device()\n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgWFuQ2MNN0N"
      },
      "source": [
        "for img, label in train_loader:\n",
        "    print(img.device)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqWAwUm5NVAO"
      },
      "source": [
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = F.cross_entropy(outputs,labels)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = F.cross_entropy(out, labels)\n",
        "        acc = accuracy(out, labels)\n",
        "        return {\"val_loss\": loss.detach(), \"val_acc\": acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [ x[\"val_loss\"] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()\n",
        "        batch_accs = [ x[\"val_acc\"] for x in outputs]\n",
        "        epoch_acc  = torch.stack(batch_accs).mean()\n",
        "        return {\"val_loss\": epoch_loss.item(), \"val_acc\": epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJk4pnlRQxAE"
      },
      "source": [
        "def conv_block(in_channel,  out_channel, pool= False):\n",
        "    layers =  [ nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1),\n",
        "                nn.BatchNorm2d(out_channel),\n",
        "                nn.LeakyReLU(0.2) ]\n",
        "    if pool: layers.append(nn.AvgPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_block(in_size, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1  = nn.Sequential( conv_block(128, 128), conv_block(128, 128))\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2  = nn.Sequential( conv_block(512, 512), conv_block(512, 512))\n",
        "        self.classifier = nn.Sequential( nn.AvgPool2d(8),\n",
        "                                         nn.Flatten(),\n",
        "                                        #  nn.Dropout(0.2),\n",
        "                                         nn.Linear(512, out_size))\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out)  +  out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out)  +  out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcAalQIeVLDT"
      },
      "source": [
        "model = to_device(ResNet9(3, 257), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqobj2obVcKC"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shEskdqmWUV1"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [ model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD ):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay= weight_decay)\n",
        "\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs,\n",
        "                                                steps_per_epoch =len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = []\n",
        "        lrs = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "\n",
        "            if grad_clip:\n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss)\n",
        "            lrs.append(get_lr(optimizer))\n",
        "\n",
        "            sched.step()\n",
        "        \n",
        "        # validation Step\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['lr'] = lrs \n",
        "        result['train_loss'] = torch.stack(train_loss).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOsRh2-Ea-BE"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIuz7wAJbBR_"
      },
      "source": [
        "epochs = 40\n",
        "weight_decay = 1e-4\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "opt_func = torch.optim.Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwzoGoP1gFJ-"
      },
      "source": [
        "history += fit(epochs, max_lr, model, train_loader, val_loader,\n",
        "               weight_decay=weight_decay, grad_clip=grad_clip, opt_func=opt_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jftocSsdgXeT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}